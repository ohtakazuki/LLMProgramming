{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ['API_KEY']\n",
    "model_name = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本のAPIリクエスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7WBswt8eRIIKMAlutTPZoa685088R at 0x22cd8ec1c70> JSON: {\n",
       "  \"id\": \"chatcmpl-7WBswt8eRIIKMAlutTPZoa685088R\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1687906538,\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"\\u4ee5\\u4e0b\\u306e\\u901a\\u308a\\u3067\\u3059\\u3002\\n\\n1. \\u5927\\u91cf\\u306e\\u30c7\\u30fc\\u30bf\\u304c\\u5fc5\\u8981\\uff1a\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306f\\u5927\\u91cf\\u306e\\u30c6\\u30ad\\u30b9\\u30c8\\u30c7\\u30fc\\u30bf\\u3092\\u5b66\\u7fd2\\u3059\\u308b\\u305f\\u3081\\u3001\\u305d\\u306e\\u305f\\u3081\\u306e\\u30c7\\u30fc\\u30bf\\u304c\\u5fc5\\u8981\\u3067\\u3059\\u3002\\n\\n2. \\u30e2\\u30c7\\u30eb\\u306e\\u7cbe\\u5ea6\\u306b\\u95a2\\u3059\\u308b\\u30c8\\u30ec\\u30fc\\u30c9\\u30aa\\u30d5\\uff1a\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306f\\u3001\\u3088\\u308a\\u6b63\\u78ba\\u306a\\u4e88\\u6e2c\\u3092\\u884c\\u3046\\u305f\\u3081\\u306b\\u6c42\\u3081\\u3089\\u308c\\u308b\\u8a08\\u7b97\\u91cf\\u304c\\u5897\\u52a0\\u3059\\u308b\\u305f\\u3081\\u3001\\u7cbe\\u5ea6\\u3068\\u901f\\u5ea6\\u306e\\u30c8\\u30ec\\u30fc\\u30c9\\u30aa\\u30d5\\u3092\\u8003\\u616e\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n3. \\u8a00\\u8a9e\\u7279\\u6027\\u306e\\u8003\\u616e\\uff1a\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306f\\u305d\\u306e\\u8a00\\u8a9e\\u306e\\u7279\\u6027\\u306b\\u5408\\u308f\\u305b\\u3066\\u8a2d\\u8a08\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\u305f\\u3068\\u3048\\u3070\\u3001\\u30a2\\u30b8\\u30a2\\u306e\\u8a00\\u8a9e\\u3067\\u306f\\u6587\\u7ae0\\u306e\\u5f62\\u5f0f\\u304c\\u7570\\u306a\\u308a\\u3001\\u8a00\\u8449\\u306e\\u8868\\u73fe\\u306b\\u72ec\\u81ea\\u306e\\u7279\\u5fb4\\u304c\\u3042\\u308b\\u305f\\u3081\\u3001\\u305d\\u308c\\u3089\\u3092\\u7279\\u5225\\u306a\\u6271\\u3044\\u3092\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\n\\n4. \\u30e2\\u30c7\\u30eb\\u306e\\u5bfe\\u8c61\\u3068\\u3059\\u308b\\u76ee\\u7684\\u306b\\u5fdc\\u3058\\u305f\\u7528\\u9014\\uff1a\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306e\\u5229\\u7528\\u76ee\\u7684\\u306b\\u5fdc\\u3058\\u305f\\u5206\\u91ce\\u3054\\u3068\\u306e\\u30e2\\u30c7\\u30eb\\u3092\\u9078\\u629e\\u3059\\u308b\\u3053\\u3068\\u3067\\u3001\\u7cbe\\u5ea6\\u3092\\u9ad8\\u3081\\u308b\\u3053\\u3068\\u304c\\u3067\\u304d\\u307e\\u3059\\u3002\\u305f\\u3068\\u3048\\u3070\\u3001\\u533b\\u7642\\u5206\\u91ce\\u3067\\u306f\\u5c02\\u9580\\u7528\\u8a9e\\u304c\\u983b\\u7e41\\u306b\\u4f7f\\u308f\\u308c\\u308b\\u3053\\u3068\\u304c\\u591a\\u304f\\u3001\\u305d\\u308c\\u3092\\u542b\\u3080\\u3088\\u3046\\u306b\\u30e2\\u30c7\\u30eb\\u3092\\u8abf\\u6574\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308b\\u304b\\u3082\\u3057\\u308c\\u307e\\u305b\\u3093\\u3002\\n\\n5. \\u30e2\\u30c7\\u30eb\\u306e\\u8a55\\u4fa1\\u3084\\u6539\\u5584\\u306b\\u5bfe\\u3059\\u308b\\u8ffd\\u8de1\\uff1a\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306b\\u3088\\u308b\\u7cbe\\u5ea6\\u6539\\u5584\\u306e\\u305f\\u3081\\u306b\\u3001\\u9069\\u5207\\u306a\\u6307\\u6a19\\u3092\\u9078\\u629e\\u3057\\u3066\\u30e2\\u30c7\\u30eb\\u306e\\u8a55\\u4fa1\\u3084\\u6539\\u5584\\u306e\\u8ffd\\u8de1\\u3092\\u884c\\u3046\\u3053\\u3068\\u304c\\u5fc5\\u8981\\u3067\\u3059\\u3002\\u4e00\\u822c\\u7684\\u306a\\u6307\\u6a19\\u306f\\u3001\\u8a00\\u8a9e\\u30e2\\u30c7\\u30eb\\u306e\\u30d1\\u30d5\\u30a9\\u30fc\\u30de\\u30f3\\u30b9\\u3092\\u8a55\\u4fa1\\u3059\\u308b\\u305f\\u3081\\u306e\\u958b\\u767a\\u7528\\u30c7\\u30fc\\u30bf\\u30bb\\u30c3\\u30c8\\u306e\\u691c\\u8a3c\\u3067\\u3042\\u308a\\u3001\\u305d\\u306e\\u305f\\u3081\\u306b\\u306f\\u3001\\u4e88\\u6e2c\\u7d50\\u679c\\u3068\\u6b63\\u89e3\\u3092\\u6bd4\\u8f03\\u3059\\u308b\\u5fc5\\u8981\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 25,\n",
       "    \"completion_tokens\": 557,\n",
       "    \"total_tokens\": 582\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下の通りです。\n",
      "\n",
      "1. 大量のデータが必要：言語モデルは大量のテキストデータを学習するため、そのためのデータが必要です。\n",
      "\n",
      "2. モデルの精度に関するトレードオフ：言語モデルは、より正確な予測を行うために求められる計算量が増加するため、精度と速度のトレードオフを考慮する必要があります。\n",
      "\n",
      "3. 言語特性の考慮：言語モデルはその言語の特性に合わせて設計する必要があります。たとえば、アジアの言語では文章の形式が異なり、言葉の表現に独自の特徴があるため、それらを特別な扱いをする必要があります。\n",
      "\n",
      "4. モデルの対象とする目的に応じた用途：言語モデルの利用目的に応じた分野ごとのモデルを選択することで、精度を高めることができます。たとえば、医療分野では専門用語が頻繁に使われることが多く、それを含むようにモデルを調整する必要があるかもしれません。\n",
      "\n",
      "5. モデルの評価や改善に対する追跡：言語モデルによる精度改善のために、適切な指標を選択してモデルの評価や改善の追跡を行うことが必要です。一般的な指標は、言語モデルのパフォーマンスを評価するための開発用データセットの検証であり、そのためには、予測結果と正解を比較する必要があります。\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルからの回答を表示\n",
    "print(response.choices[0][\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 役割や前提の設定、パラメーター：n、max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おおきに！昼食にはたこ焼き、お好み焼き、串カツなどの関西名物がおすすめです。ご飯ものであれば、カツ丼や天丼、うどん、そばも美味しいですよ。もちろん、たくさんの美味しいお店があるので、お\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、焼きそば、うどんやそば、おにぎりなどの軽食から、お寿司や天ぷら、牛丼などの定食まで様々です。特に、大阪のソウルフードであるたこ\n",
      "--------------------\n",
      "お昼ご飯ですかぁ〜。せやなぁ〜。私がおすすめするのは、大阪王将の餃子定食やで！餃子がとっても美味しいでぇー！他にも、たこ焼きやお好み焼きもオススメや！大阪に来たら、ぜひ\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：temperature, top_p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temperature=1.4の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おおきに！昼食おすすめはなにもんがある！\n",
      "\n",
      "一番クラシックなランチョンセットでもアリよ。たとえば、とんかつ定食やカレー、焼き肉定食などはどうですか？店によってセットの内容が違うと思うけど、全部が大盛のオプシ\n",
      "--------------------\n",
      "おおきに！私がおすすめする昼食は、たこ焼きやたい焼き、明石焼き、お好み焼き、串カツ、焼きそば、うどん、天ぷらなど、関西で人気のあるお好みのメニューです！せっかく関西に来たのですから、ぜ\n",
      "--------------------\n",
      "やっぱり、大阪といえばたこ焼きやお好み焼きなどがとても有名ですね。でもお昼には少し重たいかもしれませんね。\n",
      "\n",
      "そこで、あまり重たくないけど大阪らしいお昼ごはんというと、たとえば「串カツ」がお\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temperature=0.0の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。大阪には美味しい食べ物がたくさんあるので、ぜひ色\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。大阪には美味しい食べ物がたくさんあるので、ぜひ色\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。大阪には美味しい食べ物がたくさんあるので、ぜひ色\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_p=0.4の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、焼きそばなどの大阪名物の屋台料理がおすすめです。また、カツカレーやうどん、そばなどの定番の日本食も美味しいですよ。どこかおすすめのお店があれば、\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。どれも美味しいので、お好みに合わせて選んでみてください。また、大\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、焼きそばなどの大阪名物の屋台料理がおすすめです。また、カツカレーやうどん、そばなどの定番の日本食も美味しいですよ。大阪にはたくさんの飲食店があり\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    top_p=0.4\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_p=0.0の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。大阪には美味しい食べ物がたくさんあるので、ぜひ色\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。大阪には美味しい食べ物がたくさんあるので、ぜひ色\n",
      "--------------------\n",
      "おすすめの昼食は、たこ焼きやお好み焼き、うどん、そば、カツ丼、天丼、焼きそば、焼き鳥、おにぎり、お弁当などがあります。大阪には美味しい食べ物がたくさんあるので、ぜひ色\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    top_p=0.0\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：presence_penalty、frequency_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "以下のようなポイントがあります。\n",
      "\n",
      "1. データの品質：言語モデルの品質は、モデルが学習するデータの品質に大きく依存します。品質の高い大規模なデータセットを使用することが重要です。\n",
      "\n",
      "2. ハイパーパラメータ\n",
      "--------------------\n",
      "以下の通りです。\n",
      "\n",
      "1. データの質を確保すること: 言語モデルの性能は、トレーニングに使われるデータの質に大きく依存します。データの収集やラベリングには注意を払い、精度の高いデータを集めることが重\n",
      "--------------------\n",
      "次のとおりです。\n",
      "\n",
      "1.トレーニングデータの品質向上：トレーニングデータの品質が言語モデルの性能に直接関係しており、品質が向上すると、モデルの性能も向上します。\n",
      "\n",
      "2.データの前処理：言語モデルに必要な\n"
     ]
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    presence_penalty=-2.0\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "以下のようなポイントがあります。\n",
      "\n",
      "1. データセットの選択と前処理\n",
      "\n",
      "言語モデルを構築するためには、十分な量の適切に整形されたテキストデータが必要です。このため、まずはデータセットの選択と前処理が重\n",
      "--------------------\n",
      "以下の通りです。\n",
      "\n",
      "1.データセットの品質を確認する：言語モデルは、学習に使用されたデータセットに基づいてテキストを生成します。したがって、良質なデータセットが必要であり、入力テキストが文法的に正しく、意味があるこ\n",
      "--------------------\n",
      "以下の通りです：\n",
      "\n",
      "1. データセットをよく理解すること：言語モデルは、訓練に使用する大量のテキストデータが非常に重要です。したがって、データセットを選択し、分析してからモデルをトレーニングする必要があります。\n",
      "\n",
      "2. サイズ\n"
     ]
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    presence_penalty=2.0\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トークナイザー：tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "# OpenAI APIの特定のモデルに対応するトークナイザーを取得\n",
    "encoding: Encoding = tiktoken.encoding_for_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_count=9\n",
      "tokens=[90115, 6447, 78244, 45918, 252, 2845, 95, 68408, 33710]\n"
     ]
    }
   ],
   "source": [
    "# テキストをトークンIDのリストに変換\n",
    "tokens = encoding.encode(\"こんにちは！言語モデル\")\n",
    "tokens_count = len(tokens)\n",
    "# トークンの長さとトークンを表示\n",
    "print(f\"{tokens_count=}\")\n",
    "print(f\"{tokens=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは, ！, 言, b'\\xe8\\xaa', b'\\x9e', b'\\xe3\\x83', b'\\xa2', デ, ル, "
     ]
    }
   ],
   "source": [
    "# トークンの単位を確認\n",
    "for token in tokens:\n",
    "    # トークンをバイト列にデコード\n",
    "    bytes = encoding.decode_tokens_bytes([token])[0]\n",
    "    # 文字に変換できるものは変換して表示\n",
    "    try:\n",
    "        print(bytes.decode('utf-8'), end=\", \")\n",
    "    except UnicodeDecodeError:\n",
    "        print(bytes, end=\", \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：logit_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おはよう！こんにちは！元気そうだね！最近何か面白いことがあった？\n",
      "--------------------\n",
      "おはよう！元気そうだね！最近どうしてたの？\n",
      "--------------------\n",
      "こんにちは！こんにちは！お元気ですか？\n"
     ]
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"\"\"\n",
    "AさんとBさんで会話してください。\n",
    "A:おはよう！\n",
    "B:\n",
    "\"\"\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    n=3,\n",
    "    logit_bias = {90115:8, 6447:8}\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメーター：stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "おっしゃる通りやで！昼食のおすすめは、\n",
      "--------------------\n",
      "おすすめの昼食といえば、\n",
      "--------------------\n",
      "お昼ご飯におすすめなのは、「\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": role},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    n=3,\n",
    "    max_tokens=100,\n",
    "    stop=\"たこ焼き\"\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice[\"message\"][\"content\"].strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメーター：stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "いくつかのポイントがあります。以下にいくつかのポイントを挙げます。\n",
      "\n",
      "1. データセットの選択: 言語モデルを訓練するためには大量のテキストデータが必要です。より多様なテキストデータを用いることで、より一般的な言語モデルを構築することができます。\n",
      "\n",
      "2. モデルのアーキテクチャ: 言語モデルのアーキテクチャは、RNN（再帰型ニューラルネットワーク）、Transformerなどのいくつかの選択肢があります。特定のタスクや要件に応じて、最適なモデルを選択する必要があります。\n",
      "\n",
      "3. ハイパーパラメータのチューニング: 学習率、バッチサイズ、隠れ層の数などのハイパーパラメータは、言語モデルのパフォーマンスに重要な影響を与えます。適切なハイパーパラメータを選択するために、モデルを評価し、チューニングする必要があります。\n",
      "\n",
      "4. トレーニングと評価: モデルをトレーニングするときには、トレーニングデータセットを使用してモデルを学習させます。一般的に、データセットをトレーニング用と検証用に分け、モデルのパフォーマンスを評価します。トレーニング中に過学習にならないように注意する必要があります。\n",
      "\n",
      "5. 転移学習とファインチューニング: 予め他の大規模なデータセットでトレーニングされた言語モデルを使用することで、より効率的にモデルをトレーニングできます。その後、ターゲットタスクに関連するデータセットでさらにトレーニングを行うことで、モデルを特定のタスクに適応させることができます。\n",
      "\n",
      "6. データの前処理: テキストデータをモデルに入力する前に、適切な前処理が必要です。これには、トークン化、単語の埋め込み表現、パディングなどが含まれます。適切な前処理を行うことで、モデルのパフォーマンスを向上させることができます。\n",
      "\n",
      "7. モデルの評価とチューニング: 言語モデルのパフォーマンスを評価するために、適切な評価指標（例：パープレキシティ、BLEUスコアなど）を選択し、モデルを評価する必要があります。また、必要に応じてモデルをチューニングするための反復的なプロセスを行うことも重要です。"
     ]
    }
   ],
   "source": [
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    next = chunk['choices'][0]['delta'].get('content', '')\n",
    "    print(next, end='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 会話を続ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'質問:こんにちは！'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！お元気ですか？何かお手伝いできますか？"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'質問:おすすめのランチを教えて'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "もちろんです！どのような料理が好きですか？和食、洋食、中華料理など、お好みのジャンルを教えていただけると、より具体的なおすすめをお伝えできますよ！"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'質問:和食'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和食がお好きですね！以下にいくつかのおすすめのランチをご紹介します。\n",
      "\n",
      "1. 寿司ランチ: 新鮮なネタの盛り合わせや、お好みの寿司を選べるセットランチはいかがですか？寿司職人の技が光る美味しい一品を楽しめます。\n",
      "\n",
      "2. 丼もの: 牛丼、親子丼、天丼など、お好きな丼ものを選んでみてください。具材がたっぷりと乗っていて、ごはんとの相性も抜群です。\n",
      "\n",
      "3. 焼肉ランチ: カルビやハラミ、ロースなどの焼肉をランチセットで楽しむのもおすすめです。焼き立てのお肉の香りとジューシーさがたまりません。\n",
      "\n",
      "4. お蕎麦: 温かいお蕎麦やざる蕎麦、天ぷらを添えた蕎麦など、季節に応じて楽しめるお蕎麦もおすすめです。さっぱりとした味わいが優雅なランチタイムを演出してくれます。\n",
      "\n",
      "これらの和食のランチメニューは、地域やお店によって多様性がありますので、お近くのお店でぜひお試しください！\n",
      "---ご利用ありがとうございました！---\n"
     ]
    }
   ],
   "source": [
    "# メッセージを格納するリスト\n",
    "messages=[]\n",
    "\n",
    "while(True):\n",
    "    # ユーザーからの質問を受付\n",
    "    message = input(\"メッセージを入力:\")\n",
    "    # 質問が入力されなければ終了\n",
    "    if message.strip()==\"\":\n",
    "        break\n",
    "    display(f\"質問:{message}\")\n",
    "\n",
    "    # メッセージにユーザーからの質問を追加\n",
    "    messages.append({\"role\": \"user\", \"content\": message.strip()})\n",
    "    # やりとりが8を超えたら古いメッセージから削除\n",
    "    if len(messages) > 8:\n",
    "        del_message = messages.pop(0)\n",
    "\n",
    "    # APIへリクエスト\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    # 言語モデルからの回答を表示\n",
    "    response_message = \"\"\n",
    "    for chunk in response:\n",
    "        next = chunk['choices'][0]['delta'].get('content', '')\n",
    "        response_message += next\n",
    "        print(next, end='')\n",
    "\n",
    "    # メッセージに言語モデルからの回答を追加\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_message})\n",
    "\n",
    "print(\"\\n---ご利用ありがとうございました！---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
