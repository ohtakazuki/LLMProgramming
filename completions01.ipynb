{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completions API\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 環境変数の取得\n",
    "load_dotenv()\n",
    "# OpenAI APIクライアントを生成\n",
    "client = OpenAI(api_key=os.environ['API_KEY'])\n",
    "\n",
    "# モデル名\n",
    "model_name = \"gpt-3.5-turbo-instruct\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：prompt、echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "言語モデルを使う上でのポイントは、長文を短文に分割し、長文を入力する際のメモリ性質を改善できることです。\n",
      "\n",
      "これは、短い文の方が長い文よりもトークン数が少ないため、モデルの入力データのサイズが小さくなることによって、メモリ使用量を減らすことができます。\n",
      "\n",
      "また、長文を短文に分割することで、モデルがより局所的な文脈を学習することができるようになります。これにより、入力文の論理性や文章の流れを考慮できるようになり、より自然な文章を生成することができます。\n",
      "\n",
      "さらに、モデルが短文によりよく適合するように、長文を分割する際には文の意味や文法的なつながりを損なわないように注意する必要があります。例えば、文の最後の\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=300,\n",
    "    echo=True\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "、\n",
      "\n",
      "1. データセットの質\n",
      "言語モデルは、大量のテキストデータから学習するため、データセットの質が重要です。データセットは、文法的に正しい文や意味を持つ文で構成されていることが重要です。\n",
      "\n",
      "2. データの前処理\n",
      "データセットをモデルに入力する前に、テキストデータをトークン化し、特殊トークンを追加するなどの前処理を行う必要があります。また、データセットをモデルに入力する際には、学習に適した形式に変換することも重要です。\n",
      "\n",
      "3. ハイパーパラメータの調整\n",
      "言語モデルには、学習率やバッチサイズなどのハイパーパラメータが存在します。これらの値を適切に調整することで、より良いモデルを作ることがで\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "# 末尾文字の設定\n",
    "suffix = \"を続けることです。\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=300,\n",
    "    suffix=suffix\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：best_of\n",
    "\n",
    "\n",
    "### 指定しない場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "そもそも学習し直したモデルを使用する\n",
      "\n",
      "モデルの入力データとして、トークン化（トークナイズ）されたもの\n",
      "--------------------\n",
      "、まずモデルにテキストを入力すると、\n",
      "それを数値データに変換してそのまま順番に計算を行うことができ\n",
      "CompletionUsage(completion_tokens=100, prompt_tokens=17, total_tokens=117)\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=50,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.text.strip())\n",
    "\n",
    "print(response.usage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "次の ２点となります。\n",
      "\n",
      "- トークン集合から文書を生成するように訓練された言語モデルのバリデーション\n",
      "--------------------\n",
      "2つあります。\n",
      "- 一つ目は、単語のインデックスを異なる値に設定し直して始める必要があることです。 言\n",
      "CompletionUsage(completion_tokens=200, prompt_tokens=17, total_tokens=217)\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=50,\n",
    "    n=2,\n",
    "    best_of=4\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.text.strip())\n",
    "\n",
    "print(response.usage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "店長です。お問い合わせありがとうございます。是非サンプルでご覧いただくことができると嬉しいです。商品をお届けするためのご注文方法については、以下の通りです。\n",
      "\n",
      "1. 当店の商品ページから商品を選択してください。\n",
      "商品ページから、ご希望の商品を選\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"こんにちは！\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    logprobs=3\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "# OpenAI APIの特定のモデルに対応するトークナイザーを取得\n",
    "encoding: Encoding = tiktoken.encoding_for_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 店 ] [ bytes:\\xe9\\x95 ] [ bytes:\\xb7 ] [ です ] [ 。 ] [ お ] [ 問 ] [ い ] [ 合 ] [ わ ] [ せ ] [ ありがとうござ ] [ います ] [ 。 ] [ 是 ] [ 非 ] [ サ ] [ ン ] [ プ ] [ ル ] [ で ] [ ご ] [ bytes:\\xe8\\xa6 ] [ bytes:\\xa7 ] [ い ] [ ただ ] [ く ] [ こ ] [ と ] [ が ] [ で ] [ き ] [ る ] [ と ] [ bytes:\\xe5 ] [ bytes:\\xac ] [ bytes:\\x89 ] [ し ] [ い ] [ です ] [ 。 ] [ 商品 ] [ を ] [ お ] [ bytes:\\xe5\\xb1 ] [ bytes:\\x8a ] [ け ] [ する ] [ た ] [ め ] [ の ] [ ご ] [ 注 ] [ 文 ] [ 方法 ] [ に ] [ つ ] [ い ] [ て ] [ は ] [ 、 ] [ 以下 ] [ の ] [ 通 ] [ り ] [ です ] [ 。 ] [ 1 ] [ . ] [  当 ] [ 店 ] [ の ] [ 商品 ] [ ペ ] [ ージ ] [ から ] [ 商品 ] [ を ] [ bytes:\\xe9\\x81 ] [ bytes:\\xb8 ] [ bytes:\\xe6\\x8a ] [ bytes:\\x9e ] [ して ] [ ください ] [ 。 ] [ 商品 ] [ ペ ] [ ージ ] [ から ] [ 、 ] [ ご ] [ bytes:\\xe5\\xb8 ] [ bytes:\\x8c ] [ bytes:\\xe6\\x9c ] [ bytes:\\x9b ] [ の ] [ 商品 ] [ を ] [ bytes:\\xe9\\x81 ] [ bytes:\\xb8 ] "
     ]
    }
   ],
   "source": [
    "# 回答をトークンごとに確認\n",
    "for token in response.choices[0].logprobs.tokens:\n",
    "    print(\"[\", token.replace(\"\\n\",\"\"), \"]\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7.94527, -0.06836766, -6.7901296e-05, -2.578664, -1.4273841]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 選択されたトークンの確率を表示\n",
    "response.choices[0].logprobs.token_logprobs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'\\n': -1.2489457, '\\n\\n': -1.9408288, '私': -2.881209},\n",
       " {'bytes:\\\\xe9\\\\x95': -0.06836766,\n",
       "  'bytes:\\\\xe8\\\\x88': -3.5561988,\n",
       "  'bytes:\\\\xe5\\\\x93': -4.3107667},\n",
       " {'bytes:\\\\xb7': -6.7901296e-05,\n",
       "  'bytes:\\\\xb7\\\\xe6\\\\x96\\\\xb0': -9.606803,\n",
       "  'bytes:\\\\x87': -15.117227},\n",
       " {'です': -2.578664, 'の': -0.14120212, 'bytes:\\\\xe5\\\\x85': -5.348876},\n",
       " {'。': -1.4273841, '。\\n\\n': -1.107846, '！\\n\\n': -1.9637077}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# トークン上位logprobs個の確率を表示\n",
    "response.choices[0].logprobs.top_logprobs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
