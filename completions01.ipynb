{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completions API\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 環境変数の取得\n",
    "load_dotenv()\n",
    "# OpenAI APIクライアントを生成\n",
    "client = OpenAI(api_key=os.environ['API_KEY'])\n",
    "\n",
    "# モデル名\n",
    "model_name = \"gpt-3.5-turbo-instruct\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：prompt、echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "言語モデルを使う上でのポイントは，\n",
      "「どのニュースを使うか」にある．\n",
      "単にニュースを多く使えば良いというわけではない．\n",
      "例えば，あるランキングを形成する基準を，\n",
      "ランキングに加えるニュースがどれも共通して満たすとして，\n",
      "上位 4~\n",
      "位までのニュースを使って 1~\n",
      "位を予測する，というのが良い (参考文献~\\ref{list:gensim-news-crawl})．\n",
      "過学習を防ぐ意味でも．\n",
      "\n",
      "また，言語モデルを使う上での重要な点の1つが，\n",
      "言語モデルは共起確率ではなく条件付き確率であるという具体例を挙げる (参考文献~\\ref{list:word-cooccur})．\n",
      "単語共起を使った手法ではなく，単語の順序だけを使った手法として言語モデルがある．\n",
      "言語モデルに平文で使える言語\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=300,\n",
    "    echo=True\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "、\n",
      "\n",
      "1. データセットの準備\n",
      "言語モデルの学習には、豊富な量のテキストデータが必要です。そのため、使いたい言語のデータセットを収集することが重要です。\n",
      "\n",
      "2. モデルの選択\n",
      "言語モデルには、大きく分けて事前学習済みモデルと自作モデルの2つがあります。事前学習済みモデルは、すでに大量のテキストデータを用いて学習されたもので、自作モデルはデータセットを用いて学習することで作成されます。どちらを用いるかは、そのプロジェクトの目的やデータセットの規模などによって選択する必要があります。\n",
      "\n",
      "3. データの前処理\n",
      "言語モデルの学習には、データの前処理が重要です。不要な文字や単語\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "# 末尾文字の設定\n",
    "suffix = \"を続けることです。\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=300,\n",
    "    suffix=suffix\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：best_of\n",
    "\n",
    "\n",
    "### 指定しない場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "、「大量のデータを使った学習をすること」です。  \n",
      "この項目では、まず言語モデルを学習するための訓\n",
      "--------------------\n",
      "、不自然な文章を使わないという点です。\n",
      "\n",
      "まず、ここで言う「不自然な文章」とは、人間の言葉で表すとどういった\n",
      "CompletionUsage(completion_tokens=100, prompt_tokens=17, total_tokens=117)\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=50,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.text.strip())\n",
    "\n",
    "print(response.usage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "、以下の3つです。\n",
      "\n",
      "1. トークナイザ：文章を単語や文節に分割する。どのようなトークナイザを使うか\n",
      "--------------------\n",
      "2つ\n",
      "\n",
      "1つ目は「データセットを多くすること」である。\n",
      "言語モデルの良い性能を得るためには、豊富で\n",
      "CompletionUsage(completion_tokens=200, prompt_tokens=17, total_tokens=217)\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=50,\n",
    "    n=2,\n",
    "    best_of=4\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "for choice in response.choices:\n",
    "    print(\"-\" * 20)\n",
    "    print(choice.text.strip())\n",
    "\n",
    "print(response.usage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメーター：logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "稲崎です！ 先週までは天気も良いと思ったらまた雨で、寒かったのに今週の火曜日はずっと雨でドシャ降りの寒い一日になりました(;´∀｀)本当に突然。。。大量の雨が降りましたよね！！ 今\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "prompt = \"こんにちは！\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.completions.create(\n",
    "    model=model_name,\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    logprobs=3\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "# OpenAI APIの特定のモデルに対応するトークナイザーを取得\n",
    "encoding: Encoding = tiktoken.encoding_for_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ bytes:\\xe7\\xa8 ] [ bytes:\\xb2 ] [ bytes:\\xe5 ] [ bytes:\\xb4 ] [ bytes:\\x8e ] [ です ] [ ！ ] [ bytes: \\xe5\\x85 ] [ bytes:\\x88 ] [ bytes:\\xe9\\x80 ] [ bytes:\\xb1 ] [ ま ] [ では ] [ 天 ] [ 気 ] [ も ] [ bytes:\\xe8\\x89 ] [ bytes:\\xaf ] [ い ] [ と ] [ 思 ] [ っ ] [ た ] [ ら ] [ また ] [ bytes:\\xe9\\x9b ] [ bytes:\\xa8 ] [ で ] [ 、 ] [ bytes:\\xe5\\xaf ] [ bytes:\\x92 ] [ か ] [ っ ] [ た ] [ の ] [ に ] [ 今 ] [ bytes:\\xe9\\x80 ] [ bytes:\\xb1 ] [ の ] [ 火 ] [ bytes:\\xe6\\x9b ] [ bytes:\\x9c ] [ 日 ] [ は ] [ bytes:\\xe3\\x81 ] [ bytes:\\x9a ] [ っ ] [ と ] [ bytes:\\xe9\\x9b ] [ bytes:\\xa8 ] [ で ] [ ド ] [ シ ] [ ャ ] [ bytes:\\xe9\\x99 ] [ bytes:\\x8d ] [ り ] [ の ] [ bytes:\\xe5\\xaf ] [ bytes:\\x92 ] [ い ] [ 一 ] [ 日 ] [ に ] [ な ] [ り ] [ ました ] [ (; ] [ ´ ] [ bytes:\\xe2\\x88 ] [ bytes:\\x80 ] [ bytes:\\xef\\xbd ] [ bytes:\\x80 ] [ ) ] [ 本 ] [ 当 ] [ に ] [ bytes:\\xe7\\xaa ] [ bytes:\\x81 ] [ 然 ] [ 。。 ] [ 。 ] [ 大 ] [ 量 ] [ の ] [ bytes:\\xe9\\x9b ] [ bytes:\\xa8 ] [ が ] [ bytes:\\xe9\\x99 ] [ bytes:\\x8d ] [ り ] [ ました ] [ よ ] [ bytes:\\xe3\\x81 ] [ bytes:\\xad ] [ ！！ ] [   ] [ 今 ] [ bytes:\\xe9\\x80 ] "
     ]
    }
   ],
   "source": [
    "# 回答をトークンごとに確認\n",
    "for token in response.choices[0].logprobs.tokens:\n",
    "    print(\"[\", token.replace(\"\\n\",\"\"), \"]\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-9999.0, -0.36752188, -1.7257777, -4.484301, -5.419287e-05]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 選択されたトークンの確率を表示\n",
    "response.choices[0].logprobs.token_logprobs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'\\n': -1.2493514, '\\n\\n': -1.9412345, '私': -2.8816147},\n",
       " {'bytes:\\\\xb2': -0.36752188,\n",
       "  'bytes:\\\\xbc': -1.8853976,\n",
       "  'bytes:\\\\xae': -2.3355508},\n",
       " {'bytes:\\\\xe8': -1.6830589,\n",
       "  'bytes:\\\\xe5': -1.7257777,\n",
       "  'bytes:\\\\xe6\\\\x9d': -2.5654955},\n",
       " {'bytes:\\\\x9e': -0.0988128,\n",
       "  'bytes:\\\\xa6': -2.773198,\n",
       "  'bytes:\\\\xb6': -4.2145944},\n",
       " {'bytes:\\\\x8e': -5.419287e-05,\n",
       "  'bytes:\\\\x87': -10.315457,\n",
       "  'bytes:\\\\x97': -11.621781}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# トークン上位logprobs個の確率を表示\n",
    "response.choices[0].logprobs.top_logprobs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
