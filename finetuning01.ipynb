{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ファインチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 環境変数の取得\n",
    "load_dotenv()\n",
    "# OpenAI APIクライアントを生成\n",
    "client = OpenAI(api_key=os.environ['API_KEY'])\n",
    "\n",
    "# モデル名\n",
    "model_name = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データのチェック\n",
    "\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 10\n",
      "First example:\n",
      "{'role': 'user', 'content': 'どさ？'}\n",
      "{'role': 'assistant', 'content': 'どこへ？'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"training.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データの作成とアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-URwxTOD3lfGosEOFExxd0nLw', bytes=1122, created_at=1714094068, filename='training.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データのアップロード\n",
    "client.files.create(\n",
    "  file=open(\"training.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファインチューニングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ANXwpZTxixF3Bw14g9shpPe8', created_at=1714094120, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=[], seed=1278756182, status='validating_files', trained_tokens=None, training_file='file-URwxTOD3lfGosEOFExxd0nLw', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ファインチューニングジョブの開始\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file = \"file-URwxTOD3lfGosEOFExxd0nLw\", \n",
    "  model = model_name\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状況確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-ANXwpZTxixF3Bw14g9shpPe8', created_at=1714094120, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=[], seed=1278756182, status='running', trained_tokens=None, training_file='file-URwxTOD3lfGosEOFExxd0nLw', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=1714094430), FineTuningJob(id='ftjob-RUV9KV8LRt0a4kMaanI2laLF', created_at=1704612536, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-1106:personal::8eHyTOMW', finished_at=1704612904, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=['file-5IjLsFd8idgDo0V6EzbNp8Si'], seed=None, status='succeeded', trained_tokens=1970, training_file='file-7WHeNOxALRxBQPrk7PKPHwPE', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ANXwpZTxixF3Bw14g9shpPe8', created_at=1714094120, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=[], seed=1278756182, status='running', trained_tokens=None, training_file='file-URwxTOD3lfGosEOFExxd0nLw', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=1714094449)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-ANXwpZTxixF3Bw14g9shpPe8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-ANXwpZTxixF3Bw14g9shpPe8', created_at=1714094120, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9I4Xm8Rw', finished_at=1714094397, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=['file-g13Q3me3yBvGXAJMoRgu6tIp'], seed=1278756182, status='succeeded', trained_tokens=1970, training_file='file-URwxTOD3lfGosEOFExxd0nLw', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None), FineTuningJob(id='ftjob-RUV9KV8LRt0a4kMaanI2laLF', created_at=1704612536, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-1106:personal::8eHyTOMW', finished_at=1704612904, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=['file-5IjLsFd8idgDo0V6EzbNp8Si'], seed=None, status='succeeded', trained_tokens=1970, training_file='file-7WHeNOxALRxBQPrk7PKPHwPE', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ANXwpZTxixF3Bw14g9shpPe8', created_at=1714094120, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal::9I4Xm8Rw', finished_at=1714094397, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-xPjRpwlrimJbMHBKNimdi7UM', result_files=['file-g13Q3me3yBvGXAJMoRgu6tIp'], seed=1278756182, status='succeeded', trained_tokens=1970, training_file='file-URwxTOD3lfGosEOFExxd0nLw', validation_file=None, integrations=[], user_provided_suffix=None, estimated_finish=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-ANXwpZTxixF3Bw14g9shpPe8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファインチューニング済モデルの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "イライラする\n"
     ]
    }
   ],
   "source": [
    "# プロンプトの設定\n",
    "content = \"「かちゃくちゃねぇ」の意味は？\"\n",
    "\n",
    "# APIへリクエスト\n",
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::9I4Xm8Rw\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": content}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
