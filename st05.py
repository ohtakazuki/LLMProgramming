# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os
from dotenv import load_dotenv
from openai import OpenAI
import streamlit as st

# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
load_dotenv()
# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆ
client = OpenAI(api_key=os.environ['API_KEY'])

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ’¬ Chatbot")

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆãŒç©ºãªã‚‰åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨­å®š
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ã‚ˆã†ã“ãï¼ã”è¦ä»¶ã¯ä½•ã§ã™ã‹ï¼Ÿ"}]

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®å†…å®¹ã‚’ãƒãƒ£ãƒƒãƒˆè¦ç´ ã«è¡¨ç¤º
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’promptã«ä»£å…¥ã‹ã¤åˆ¤å®š
if prompt := st.chat_input():
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã‚’ãƒãƒ£ãƒƒãƒˆè¦ç´ ã«è¡¨ç¤º
    st.chat_message("user").write(prompt)

    # è¨€èªãƒ¢ãƒ‡ãƒ«ã¸ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    response = client.chat.completions.create(
        model="gpt-3.5-turbo-1106",
        messages=st.session_state.messages,
        stream=True)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_message = ""

        # è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å›ç­”ã‚’å–å¾—
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
              full_message += chunk.choices[0].delta.content
            message_placeholder.markdown(full_message + "â–Œ")

        message_placeholder.markdown(full_message)

        # è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": full_message})