{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. モデルの型について、自然言語処理の目的やコンテキストに応じた適切なモデルを用いること。\n",
      "\n",
      "2. モデルのコードについて、モデル設計の効率性や汎用性を高めるために高度なアルゴリズムを用いること。\n",
      "\n",
      "3. データセットの種類や規模について、関連性を持つような蓄積されたデータでモデルを訓練して得られる正確な結果を得ようとすること。\n",
      "\n",
      "4. モデルトレーニングを行うときについて、損失関数や正則化項などの各パラメーターを実験的に\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "model_name = \"text-davinci-003\"\n",
    "\n",
    "# プロンプトの設定\n",
    "prompt = \"言語モデルを使う上でのポイントは？\"\n",
    "\n",
    "# モデルの作成\n",
    "llm = OpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)\n",
    "\n",
    "# 言語モデルへリクエスト\n",
    "response = llm(prompt)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='言語モデルを使う際のポイントは以下のとおりです。\\n\\n1. データの準備: 言語モデルを訓練するためには、大量のテキストデータが必要です。データの質と量を向上させるため、言語を対象とした専門的なデータセットを選択することが重要です。\\n\\n2. モデルの選択: 言語モデルには、RNN（再帰型ニューラルネットワーク）やTransformerなどさまざまなアーキテクチャがあります。対象のタスクや利用目的に合わせて、適切なモデルを選択しましょう。\\n\\n3. ハイパーパラメータの調整: 言語モデルの性能を最適化するためには、ハイパーパラメータの調整が必要です。学習率やバッチサイズなど、' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "# メッセージの設定\n",
    "message = \"言語モデルを使う上でのポイントは？\"\n",
    "\n",
    "# 言語モデルの作成\n",
    "chat = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    temperature=1.2,\n",
    "    max_tokens=300)\n",
    "\n",
    "# 言語モデルへリクエスト\n",
    "response = chat.predict_messages([\n",
    "    HumanMessage(content=message)])\n",
    "\n",
    "# 結果を表示（AIMessage型で返る）\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "言語モデルを使う際のポイントは以下のとおりです。\n",
      "\n",
      "1. データの準備: 言語モデルを訓練するためには、大量のテキストデータが必要です。データの質と量を向上させるため、言語を対象とした専門的なデータセットを選択することが重要です。\n",
      "\n",
      "2. モデルの選択: 言語モデルには、RNN（再帰型ニューラルネットワーク）やTransformerなどさまざまなアーキテクチャがあります。対象のタスクや利用目的に合わせて、適切なモデルを選択しましょう。\n",
      "\n",
      "3. ハイパーパラメータの調整: 言語モデルの性能を最適化するためには、ハイパーパラメータの調整が必要です。学習率やバッチサイズなど、\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 役割や前提、パラメーターの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おおきに！おすすめの昼食は、たこ焼きやお好み焼き、串カツやうどんなんやで！けっこうボリュームがあって、美味しいもんばっかりやで！どれも大阪のソウルフードやから、ぜひ食べてみてや！\n"
     ]
    }
   ],
   "source": [
    "# 役割を設定\n",
    "role = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# メッセージの設定\n",
    "message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    temperature=1.2,\n",
    "    max_tokens=300)\n",
    "\n",
    "aiMessage = chat.predict_messages([\n",
    "    SystemMessage(content=role),\n",
    "    HumanMessage(content=message)])\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(aiMessage.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "せやけど、お好み焼きもたこ焼きもうどんも串カツもめっちゃ美味しいもんやで！でも、それ以外でもおすすめの昼食は、味噌カツや焼きそば、てっちり鍋やもんじゃ焼き、お寿司や刺し身なんかもおいしいで！大阪やから、たくさんのお店で様々なグルメが楽しめるで！ゆっくり食べて、関西を満喫してくれや！\n"
     ]
    }
   ],
   "source": [
    "# 会話を続ける\n",
    "response = chat.predict_messages([\n",
    "    SystemMessage(content=role),\n",
    "    HumanMessage(content=message),\n",
    "    aiMessage,\n",
    "    HumanMessage(content=\"それ以外のおすすめは？\")])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.prompts.prompt.PromptTemplate'> \n",
      " ----------------------------------------\n",
      "input_variables=['subject'] output_parser=None partial_variables={} template='{subject}を勉強する方法をステップ・バイ・ステップで教えてください' template_format='f-string' validate_template=True \n",
      " ----------------------------------------\n",
      "英語を勉強する方法をステップ・バイ・ステップで教えてください\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "model_name = \"text-davinci-003\"\n",
    "\n",
    "# プロンプトテンプレートの作成\n",
    "template = \"{subject}を勉強する方法をステップ・バイ・ステップで教えてください\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# プロンプト文字列を生成\n",
    "prompt_string = prompt.format(subject=\"英語\")\n",
    "\n",
    "# プロンプトの表示\n",
    "print(type(prompt), \"\\n\", \"-\"*40)\n",
    "print(prompt, \"\\n\", \"-\"*40)\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. ゴールとそこに到達するために必要な士気とリスクをおさえる。\n",
      "\n",
      "2. 英語の能力を客観的に評価するために、検定や短期学習に取り組むなどのさまざまな試みを試みる。\n",
      "\n",
      "3. 聞くための日常の生活での英語を楽しみ始める。たとえば英語のニュースの刊行物、書籍、あるいはその他の音楽などを聞いてみる。\n",
      "\n",
      "4. 音声の発音練習をすることを手始めに、しゃべる習慣を身に付けるために英会話クラスなど\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm(prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='あなたは英語から日本語に翻訳する優秀な翻訳家です。', additional_kwargs={}), HumanMessage(content='I love programming.', additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# システムメッセージ用プロンプトテンプレート\n",
    "prompt=PromptTemplate(\n",
    "    template=\"あなたは{input_language}から{output_language}に翻訳する優秀な翻訳家です。\",\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "# ユーザーメッセージ用プロンプトテンプレート\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "\n",
    "# Chatプロンプトの作成\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt])\n",
    "\n",
    "# チャットメッセージリストの生成\n",
    "chat_messages = chat_prompt.format_prompt(\n",
    "    input_language=\"英語\",\n",
    "    output_language=\"日本語\",\n",
    "    text=\"I love programming.\").to_messages()\n",
    "\n",
    "# メッセージリストの表示\n",
    "print(chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='私はプログラミングが大好きです。' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = chat.predict_messages(chat_messages)\n",
    "\n",
    "# 結果を表示（AIMessage型で返る）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# 抽出元のリスト\n",
    "examples = [\n",
    "    {\"input\": \"楽しい\", \"output\": \"悲しい\"},\n",
    "    {\"input\": \"高い\", \"output\": \"低い\"},\n",
    "    {\"input\": \"活発\", \"output\": \"緩慢\"},\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"心地よい\", \"output\": \"気持ち悪い\"},\n",
    "]\n",
    "\n",
    "# プロンプトテンプレート\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# Example Selector\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,  # 抽出元リスト\n",
    "    example_prompt=example_prompt,  # 適用するテンプレート\n",
    "    max_length=15, # フォーマット後の文字列の長さ\n",
    ")\n",
    "\n",
    "# Few-Shotプロンプトテンプレートを作成\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"すべての入力の対義語を与えます。\",\n",
    "    suffix=\"入力: {adjective}\\n出力:\", \n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の対義語を与えます。\n",
      "\n",
      "入力: 楽しい\n",
      "出力: 悲しい\n",
      "\n",
      "入力: 高い\n",
      "出力: 低い\n",
      "\n",
      "入力: 活発\n",
      "出力: 緩慢\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "# Few-Shotプロンプトを生成\n",
    "dynamic_prompt_string = dynamic_prompt.format(adjective=\"大きい\")\n",
    "print(dynamic_prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 小さい\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm(dynamic_prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Output Parserの作成\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "arena, archery, arrested, artery, appearance, apron, archway, arrangement, ambassador, archetype\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm(\"aで始まる英単語を10個、カンマ区切りで出力してください\")\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arena',\n",
       " 'archery',\n",
       " 'arrested',\n",
       " 'artery',\n",
       " 'appearance',\n",
       " 'apron',\n",
       " 'archway',\n",
       " 'arrangement',\n",
       " 'ambassador',\n",
       " 'archetype']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 変換\n",
    "output_parser.parse(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
