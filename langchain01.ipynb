{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# モデルの作成\n",
    "llm = OpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- 大規模なトレーニングデータを用意することで精度を向上させる\n",
      "- ダイバーシティがある幅広い単語や表現を収集し、モデルに組み込むことでより自然な表現を生成する\n",
      "- 単語や文章の出現頻度を考慮することで、コーパス内の単語間の結びつきを学習してより正確な予測を行う\n",
      "- 文脈を考慮し、単語や文章の出現頻度だけではなく、前後にくる単語や文章も学習することで、より文脈に即した表現を生成する\n",
      "- 潜在的な意味や文法的な規則などの知識を獲得するために、機械学習アルゴリズムを採用することでより高度な言語モデルを構築する\n"
     ]
    }
   ],
   "source": [
    "# 質問の設定\n",
    "text = \"言語モデルを使う上でのポイントは？\"\n",
    "\n",
    "# 言語モデルの呼出\n",
    "response = llm.invoke(text)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "# モデルの作成\n",
    "chat_model = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1. データの品質向上: 言語モデルを構築するためには大規模なデータセットが必要です。そのため、データの収集からクリーニングまで、データの品質を向上させることが重要です。\\n\\n2. ハイパーパラメータの適切な設定: 言語モデルには複数のハイパーパラメータが存在し、それらの適切な設定が重要です。適切なハイパーパラメータを探索するためには、実験を重ねる必要があります。\\n\\n3. モデルの評価: 言語モデルの品質は正確な評価が必要です。適切な評価指標を選択し、実際の応用環境におけるモデルの性能を適切に評価することが重要です。\\n\\n4. パフォ'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# 質問の設定\n",
    "text = \"言語モデルを使う上でのポイントは？\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "# 言語モデルの呼出\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 結果を表示（AIMessage型）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. データの品質向上: 言語モデルを構築するためには大規模なデータセットが必要です。そのため、データの収集からクリーニングまで、データの品質を向上させることが重要です。\n",
      "\n",
      "2. ハイパーパラメータの適切な設定: 言語モデルには複数のハイパーパラメータが存在し、それらの適切な設定が重要です。適切なハイパーパラメータを探索するためには、実験を重ねる必要があります。\n",
      "\n",
      "3. モデルの評価: 言語モデルの品質は正確な評価が必要です。適切な評価指標を選択し、実際の応用環境におけるモデルの性能を適切に評価することが重要です。\n",
      "\n",
      "4. パフォ\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 役割や前提、パラメーターの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昼飯なら、たこ焼きとお好み焼きがあんまりおすすめやねん。あとはホルモン焼きや串カツもええやろ。関西って美味しいもんいっぱいあるから迷うくらいやで。\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Systemメッセージ\n",
    "system_message = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# ユーザーからの質問\n",
    "user_message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# メッセージ配列の作成\n",
    "messages = [\n",
    "  SystemMessage(content=system_message),\n",
    "  HumanMessage(content=user_message)]\n",
    "\n",
    "# 言語モデルの呼出\n",
    "aiMessage = chat_model.invoke(messages)\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(aiMessage.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他にもおすすめとしましては、うどんやそうめんもええやろう。関西では美味しい和食や洋食もたくさんあるから、食べたいものに合わせて選ぶとええと思うで。\n"
     ]
    }
   ],
   "source": [
    "# 会話を続ける\n",
    "response = chat_model.invoke([\n",
    "  *messages,\n",
    "  aiMessage,\n",
    "  HumanMessage(content=\"それ以外のおすすめは？\")])\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'> \n",
      " ----------------------------------------\n",
      "input_variables=['subject'] template='{subject}を勉強する方法をステップ・バイ・ステップで教えてください' \n",
      " ----------------------------------------\n",
      "英語を勉強する方法をステップ・バイ・ステップで教えてください\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# プロンプトテンプレートの作成\n",
    "template = \"{subject}を勉強する方法をステップ・バイ・ステップで教えてください\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# プロンプト文字列を生成\n",
    "prompt_string = prompt.format(subject=\"英語\")\n",
    "\n",
    "# プロンプトの表示\n",
    "print(type(prompt), \"\\n\", \"-\"*40)\n",
    "print(prompt, \"\\n\", \"-\"*40)\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ステップ1: 目標を設定する\n",
      "まず最初に、英語を勉強する理由や目的を明確にしましょう。自分の英語のレベルを知り、どのように成長したいか、またはどの程度のレベルを目指すかを決めます。目標を明確にすることでモチベーションを持続させることができます。\n",
      "\n",
      "ステップ2: 日常的な学習環境を作る\n",
      "英語を勉強するための環境を整えましょう。英語の本やオーディオブック、映画やテレビ番組などを使用して、身近な環境に英語を取り入れることが重要です。また、英語を話す機会を増やすために、英語クラスや英会話グループなどに参加することも良いでしょう。\n",
      "\n",
      "ステップ3:\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルの呼出\n",
    "response = llm.invoke(prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='あなたは英語から日本語に翻訳する優秀な翻訳家です。'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"あなたは{input_language}から{output_language}に翻訳する優秀な翻訳家です。\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_language=\"英語\", output_language=\"日本語\", text=\"I love programming.\")\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='プログラミングが大好きです。'\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルの呼出\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 結果を表示（AIMessage型）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Output Parserの作成\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "afoot,adult,amaze,appear,allow,t(this!),apple,arch,attack,all\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm.invoke(\"aで始まる英単語を10個、カンマ区切りで出力してください\")\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afoot,adult,amaze,appear,allow,t(this!),apple,arch,attack,all']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 変換\n",
    "output_parser.parse(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# 抽出元のリスト\n",
    "examples = [\n",
    "    {\"input\": \"楽しい\", \"output\": \"悲しい\"},\n",
    "    {\"input\": \"高い\", \"output\": \"低い\"},\n",
    "    {\"input\": \"活発\", \"output\": \"緩慢\"},\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"心地よい\", \"output\": \"気持ち悪い\"},\n",
    "]\n",
    "\n",
    "# プロンプトテンプレート\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# Example Selector\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,  # 抽出元リスト\n",
    "    example_prompt=example_prompt,  # 適用するテンプレート\n",
    "    max_length=15, # フォーマット後の文字列の長さ\n",
    ")\n",
    "\n",
    "# Few-Shotプロンプトテンプレートを作成\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"すべての入力の対義語を与えます。\",\n",
    "    suffix=\"入力: {adjective}\\n出力:\", \n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の対義語を与えます。\n",
      "\n",
      "入力: 楽しい\n",
      "出力: 悲しい\n",
      "\n",
      "入力: 高い\n",
      "出力: 低い\n",
      "\n",
      "入力: 活発\n",
      "出力: 緩慢\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "# Few-Shotプロンプトを生成\n",
    "dynamic_prompt_string = dynamic_prompt.format(adjective=\"大きい\")\n",
    "print(dynamic_prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 小さい\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm.invoke(dynamic_prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
