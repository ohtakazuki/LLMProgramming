{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# モデルの作成\n",
    "llm = OpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 十分な大きさのコーパスを用意すること：言語モデルの性能は、提供するテキストデータ（コーパス）の量によって大きく左右されるため、コーパスの大きさを最大限にすることが重要です。また、コーパスの多様性も重要であるため、様々なジャンルや分野のテキストデータを用意することが望ましいです。\n",
      "\n",
      "2. 適切なトークン化（単語分割）を行うこと：トークン化は、文字列を単語や品詞などの意味を持つ単位に分割することで、言語モデルの学習において重要な役割を果たします。適切なトークン化を行うことで、言語モデルがより正確に単語の意味や文の構造を理解することができます。\n",
      "\n",
      "3. 語彙\n"
     ]
    }
   ],
   "source": [
    "# 質問の設定\n",
    "text = \"言語モデルを使う上でのポイントは？\"\n",
    "\n",
    "# 言語モデルの呼出\n",
    "response = llm.invoke(text)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "# モデルの作成\n",
    "chat_model = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='言語モデルを使用する際のポイントは以下の通りです：\\n\\n1. データの質：言語モデルの性能は、学習に使われるデータの質に大きく依存します。十分な量の多様なデータを用意することが重要です。\\n\\n2. パフォーマンス評価：言語モデルのパフォーマンスを評価するために、適切な指標を選択する必要があります。例えば、パープレキシティ（perplexity）やBLEUスコアなどが使われます。\\n\\n3. ハイパーパラメータの調整：言語モデルには多くのハイパーパラメータが存在し、最適な性能を得るためにはこれらのパラメータを適切に調整する必要があります。\\n\\n4. 訓練時間：言語モデルは一般的に学習に多くの時間がかかります' response_metadata={'token_usage': {'completion_tokens': 300, 'prompt_tokens': 25, 'total_tokens': 325}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'length', 'logprobs': None} id='run-3a2c112b-0de3-4e09-a7f7-908bff13b195-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 質問の設定\n",
    "text = \"言語モデルを使う上でのポイントは？\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "# 言語モデルの呼出\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 結果を表示（AIMessage型）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "言語モデルを使用する際にはいくつかのポイントに注意する必要があります。以下にそのポイントをいくつか紹介します。\n",
      "\n",
      "1. データの品質：良質なデータセットを使用することが重要です。言語モデルのパフォーマンスは、使用されるデータの量と品質に大きく依存します。\n",
      "\n",
      "2. ランゲージの選択：特定のプロジェクトやアプリケーションに適した言語モデルを選択することが重要です。一般的な言語モデルと、特定のドメインやタスクに特化した言語モデルとの違いを理解することが重要です。\n",
      "\n",
      "3. ハイパーパラメータのチューニング：言語モデルを訓練する際には、適切なハイパーパラメータを選択してパフォーマンスを最適化する必要があり\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 役割や前提、パラメーターの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昼食なら、やっぱりお好み焼きやたこ焼きがおすすめやで！美味しいし、ボリュームもあって満足度高いねん。ほかにも、うどんやラーメンもオススメやで！ええ店知っとるから、気になったら教えてくれや。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Systemメッセージ\n",
    "system_message = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# ユーザーからの質問\n",
    "user_message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# メッセージ配列の作成\n",
    "messages = [\n",
    "  SystemMessage(content=system_message),\n",
    "  HumanMessage(content=user_message)]\n",
    "\n",
    "# 言語モデルの呼出\n",
    "aiMessage = chat_model.invoke(messages)\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(aiMessage.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ええと、他にもおすすめするとしたら、串カツや焼き鳥、お寿司もええと思うで。関西には美味しいお店がたくさんあるから、ぜひ行ってみてや。気に入った店あったら友達にもオススメしてや。楽しい食べ歩きができるとええなあ。\n"
     ]
    }
   ],
   "source": [
    "# 会話を続ける\n",
    "response = chat_model.invoke([\n",
    "  *messages,\n",
    "  aiMessage,\n",
    "  HumanMessage(content=\"それ以外のおすすめは？\")])\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'> \n",
      " ----------------------------------------\n",
      "input_variables=['subject'] template='{subject}を勉強する方法をステップ・バイ・ステップで教えてください' \n",
      " ----------------------------------------\n",
      "英語を勉強する方法をステップ・バイ・ステップで教えてください\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# プロンプトテンプレートの作成\n",
    "template = \"{subject}を勉強する方法をステップ・バイ・ステップで教えてください\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# プロンプト文字列を生成\n",
    "prompt_string = prompt.format(subject=\"英語\")\n",
    "\n",
    "# プロンプトの表示\n",
    "print(type(prompt), \"\\n\", \"-\"*40)\n",
    "print(prompt, \"\\n\", \"-\"*40)\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 目的を明確にする：はじめに、なぜ英語を学びたいのか、どのようなレベルを目指すのかを明確にしましょう。英語でできるようになりたいことがはっきりしていれば、それに向けて学習の方向性を決めることができます。\n",
      "\n",
      "2. 学習の方法を選ぶ：英語を学ぶ方法は様々あります。例えば、私学や語学学校に通う、オンラインコースを受講する、フラッシュカードやオンライン辞書を活用するなどがあります。自分に合った方法を選びましょう。\n",
      "\n",
      "3. 基礎の復習をする：英語を学ぶ際に重要なのは基礎をしっかりと固めることです。文法や英単語、発音などの基本的な知識をしっかりと身に付けまし\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルの呼出\n",
    "response = llm.invoke(prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='あなたは英語から日本語に翻訳する優秀な翻訳家です。'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"あなたは{input_language}から{output_language}に翻訳する優秀な翻訳家です。\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_language=\"英語\", output_language=\"日本語\", text=\"I love programming.\")\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='プログラミングが大好きです。' response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 48, 'total_tokens': 60}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-8ce3c6c8-d46b-4af8-a965-290857f287fc-0'\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルの呼出\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 結果を表示（AIMessage型）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Output Parserの作成\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "apple, actual, Any thing, analyze, anim\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm.invoke(\"aで始まる英単語を10個、カンマ区切りで出力してください\")\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'actual', 'Any thing', 'analyze', 'anim']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 変換\n",
    "output_parser.parse(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
    "\n",
    "# 抽出元のリスト\n",
    "examples = [\n",
    "    {\"input\": \"楽しい\", \"output\": \"悲しい\"},\n",
    "    {\"input\": \"高い\", \"output\": \"低い\"},\n",
    "    {\"input\": \"活発\", \"output\": \"緩慢\"},\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"心地よい\", \"output\": \"気持ち悪い\"},\n",
    "]\n",
    "\n",
    "# プロンプトテンプレート\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# Example Selector\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,  # 抽出元リスト\n",
    "    example_prompt=example_prompt,  # 適用するテンプレート\n",
    "    max_length=15, # フォーマット後の文字列の長さ\n",
    ")\n",
    "\n",
    "# Few-Shotプロンプトテンプレートを作成\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"すべての入力の対義語を与えます。\",\n",
    "    suffix=\"入力: {adjective}\\n出力:\", \n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の対義語を与えます。\n",
      "\n",
      "入力: 楽しい\n",
      "出力: 悲しい\n",
      "\n",
      "入力: 高い\n",
      "出力: 低い\n",
      "\n",
      "入力: 活発\n",
      "出力: 緩慢\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "# Few-Shotプロンプトを生成\n",
    "dynamic_prompt_string = dynamic_prompt.format(adjective=\"大きい\")\n",
    "print(dynamic_prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 小さい\n",
      "\n",
      "入力: 美しい\n",
      "出力: 醜い\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm.invoke(dynamic_prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
