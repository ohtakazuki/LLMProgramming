{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I/O\n",
    "\n",
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# モデルの作成\n",
    "llm = OpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. データセットの選択: 言語モデルを訓\n"
     ]
    }
   ],
   "source": [
    "# 質問の設定\n",
    "text = \"言語モデルを使う上でのポイントは？\"\n",
    "\n",
    "# 言語モデルの呼出\n",
    "response = llm.invoke(text)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "# モデルの作成\n",
    "chat_model = ChatOpenAI(\n",
    "    model_name=model_name,\n",
    "    max_tokens=300,\n",
    "    temperature=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='言語モデルを使用する際にはいくつかのポイントに注意する必要があります。以下にそのポイントをいくつか紹介します。\\n\\n1. データの品質：良質なデータセットを使用することが重要です。言語モデルのパフォーマンスは、使用されるデータの量と品質に大きく依存します。\\n\\n2. ランゲージの選択：特定のプロジェクトやアプリケーションに適した言語モデルを選択することが重要です。一般的な言語モデルと、特定のドメインやタスクに特化した言語モデルとの違いを理解することが重要です。\\n\\n3. ハイパーパラメータのチューニング：言語モデルを訓練する際には、適切なハイパーパラメータを選択してパフォーマンスを最適化する必要があり' response_metadata={'token_usage': {'completion_tokens': 300, 'prompt_tokens': 25, 'total_tokens': 325}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_77a673219d', 'finish_reason': 'length', 'logprobs': None} id='run-021591b3-75cb-435b-a023-0c267cd69323-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 質問の設定\n",
    "text = \"言語モデルを使う上でのポイントは？\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "# 言語モデルの呼出\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 結果を表示（AIMessage型）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "言語モデルを使用する際にはいくつかのポイントに注意する必要があります。以下にそのポイントをいくつか紹介します。\n",
      "\n",
      "1. データの品質：良質なデータセットを使用することが重要です。言語モデルのパフォーマンスは、使用されるデータの量と品質に大きく依存します。\n",
      "\n",
      "2. ランゲージの選択：特定のプロジェクトやアプリケーションに適した言語モデルを選択することが重要です。一般的な言語モデルと、特定のドメインやタスクに特化した言語モデルとの違いを理解することが重要です。\n",
      "\n",
      "3. ハイパーパラメータのチューニング：言語モデルを訓練する際には、適切なハイパーパラメータを選択してパフォーマンスを最適化する必要があり\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 役割や前提、パラメーターの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おすすめの昼食は、たこ焼きやお好み焼き、うどんやラーメン、焼きそばやおにぎりなど、たくさんありますやん。んまいもん食べたらええで。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Systemメッセージ\n",
    "system_message = \"あなたは関西人です。大阪弁を使います。\"\n",
    "# ユーザーからの質問\n",
    "user_message = \"おすすめの昼食は何ですか？\"\n",
    "\n",
    "# メッセージ配列の作成\n",
    "messages = [\n",
    "  SystemMessage(content=system_message),\n",
    "  HumanMessage(content=user_message)]\n",
    "\n",
    "# 言語モデルの呼出\n",
    "aiMessage = chat_model.invoke(messages)\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(aiMessage.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "そうやなぁ、定番のお弁当やお寿司もおすすめやで。お弁当は手軽に食べられて、種類もたくさんあるから、好きなもんが選べるで。また、お寿司なら新鮮なネタと美味しい酢飯が最高やで。お腹いっぱい食べて、元気になってや～。\n"
     ]
    }
   ],
   "source": [
    "# 会話を続ける\n",
    "response = chat_model.invoke([\n",
    "  *messages,\n",
    "  aiMessage,\n",
    "  HumanMessage(content=\"それ以外のおすすめは？\")])\n",
    "\n",
    "# 言語モデルからの回答を表示\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'> \n",
      " ----------------------------------------\n",
      "input_variables=['subject'] template='{subject}を勉強する方法をステップ・バイ・ステップで教えてください' \n",
      " ----------------------------------------\n",
      "英語を勉強する方法をステップ・バイ・ステップで教えてください\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# プロンプトテンプレートの作成\n",
    "template = \"{subject}を勉強する方法をステップ・バイ・ステップで教えてください\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# プロンプト文字列を生成\n",
    "prompt_string = prompt.format(subject=\"英語\")\n",
    "\n",
    "# プロンプトの表示\n",
    "print(type(prompt), \"\\n\", \"-\"*40)\n",
    "print(prompt, \"\\n\", \"-\"*40)\n",
    "print(prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ステップ1: 目的を明確にする\n",
      "まず、なぜ英語を勉強するのか、どのようなレベルまで習得したいのかを明確にすることが重要です。具体的な目標を立てることで、効果的な勉強計画を立てることができます。\n",
      "\n",
      "ステップ2: 基礎的な文法を学ぶ\n",
      "文法は英語学習の基礎となります。初心者の場合は、基本的な文法ルールや品詞、動詞の時制などを学びましょう。一般的な文法書やオンラインコース、動画などを参考にするとよいでしょう。\n",
      "\n",
      "ステップ3: 語彙を増やす\n",
      "英語を上達させるには、多くの語彙を覚えることが必要です。Common wordsやAcademic wordsなど、よく使われる単語や必要な単語を定期的に\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルの呼出\n",
    "response = llm.invoke(prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='あなたは英語から日本語に翻訳する優秀な翻訳家です。'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"あなたは{input_language}から{output_language}に翻訳する優秀な翻訳家です。\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_language=\"英語\", output_language=\"日本語\", text=\"I love programming.\")\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='私はプログラミングが大好きです。' response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 48, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_b953e4de39', 'finish_reason': 'stop', 'logprobs': None} id='run-1d034251-e5a8-41fa-a7db-6a3028088c39-0'\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルの呼出\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 結果を表示（AIMessage型）\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# Output Parserの作成\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "aback,abandon,abbey,abcommon,abort,abmulbury,abnormal,abuse,abide,able\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm.invoke(\"aで始まる英単語を10個、カンマ区切りで出力してください\")\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aback,abandon,abbey,abcommon,abort,abmulbury,abnormal,abuse,abide,able']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 変換\n",
    "output_parser.parse(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
    "\n",
    "# 抽出元のリスト\n",
    "examples = [\n",
    "    {\"input\": \"楽しい\", \"output\": \"悲しい\"},\n",
    "    {\"input\": \"高い\", \"output\": \"低い\"},\n",
    "    {\"input\": \"活発\", \"output\": \"緩慢\"},\n",
    "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
    "    {\"input\": \"心地よい\", \"output\": \"気持ち悪い\"},\n",
    "]\n",
    "\n",
    "# プロンプトテンプレート\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"入力: {input}\\n出力: {output}\",\n",
    ")\n",
    "\n",
    "# Example Selector\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,  # 抽出元リスト\n",
    "    example_prompt=example_prompt,  # 適用するテンプレート\n",
    "    max_length=15, # フォーマット後の文字列の長さ\n",
    ")\n",
    "\n",
    "# Few-Shotプロンプトテンプレートを作成\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"すべての入力の対義語を与えます。\",\n",
    "    suffix=\"入力: {adjective}\\n出力:\", \n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すべての入力の対義語を与えます。\n",
      "\n",
      "入力: 楽しい\n",
      "出力: 悲しい\n",
      "\n",
      "入力: 高い\n",
      "出力: 低い\n",
      "\n",
      "入力: 活発\n",
      "出力: 緩慢\n",
      "\n",
      "入力: 大きい\n",
      "出力:\n"
     ]
    }
   ],
   "source": [
    "# Few-Shotプロンプトを生成\n",
    "dynamic_prompt_string = dynamic_prompt.format(adjective=\"大きい\")\n",
    "print(dynamic_prompt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 小さい\n"
     ]
    }
   ],
   "source": [
    "# 言語モデルへリクエスト\n",
    "response = llm.invoke(dynamic_prompt_string)\n",
    "\n",
    "# 結果を表示\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
